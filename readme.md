## Engagement Tracker
An AI-powered real-time engagement tracker that analyzes video feeds, speech activity, and user interactions. It leverages Flask and Socket.IO for a dynamic web interface, OpenCV for video processing, and MediaPipe (via a custom processor) for detecting activities and engagement levels. The system provides live dashboards and generates downloadable PDF engagement reports at the end of each session.
![Demo](https://raw.githubusercontent.com/Joshluk3328j/Engagment-tracker-v1/main/img.png)

## ğŸš€ Features

- ğŸ“¹ Real-time video streaming using OpenCV and Flask. <br>
- ğŸ§  Engagement tracking with EngageTrackVideoProcessor for face, gaze, and activity detection. <br>
- ğŸ™ï¸ Speech-to-text integration powered by the AssemblyAI API. <br>
- ğŸ”„ Live activity updates and event logs via Socket.IO. <br>
- ğŸ“‘ Session reports exported as downloadable PDFs. <br>
- ğŸŒ Web-based dashboard for monitoring participants in real time. <br>

## ğŸ› ï¸ Installation
Follow these steps to set up the Engagement Tracker on your local machine.
1. Clone the Repository
```
git clone https://github.com/yourusername/engagement-tracker.git
cd engagement-tracker
```
2. Create a Virtual Environment
```
python3 -m venv venv
source venv/bin/activate  # Linux / Mac
venv\Scripts\activate     # Windows
```
3. Install Dependencies

```
pip install -r requirements.txt
```
4. Set Environment Variables
Create a .env file in the project root and add your AssemblyAI API key:
```
ASSEMBLY_API_KEY=your_api_key_here
```

## â–¶ï¸ Running the App
Start the Flask application:
```
python app.py
```
The server will run by default at:ğŸ‘‰ http://localhost:5000
## ğŸ“‚ Project Structure
Engagement Tracker/
```
â”œâ”€â”€ app.py                    # Main Flask app entry point
â”œâ”€â”€ engage_track_video.py     # Engagement tracking video processor
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html            # Dashboard UI
â”‚   â””â”€â”€ end.html              # End-session page
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ engagement_report.pdf # Session reports stored here
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .env                      # Environment variables (AssemblyAI key)
```
## ğŸ“Š Workflow

- Video Capture: Video frames are captured using OpenCV. <br>
- Engagement Detection: Frames are processed by EngageTrackVideoProcessor for face, gaze, and activity detection. <br>
- Real-time Updates: Socket.IO emits activities and events to the client dashboard. <br>
- Session Logging: Session logs are written to disk. <br>
- Report GeneraEngagement Tracker/tion: Engagement reports are generated as downloadable PDFs. <br>

## ğŸ“¦ Dependencies

|Dependency |Description|
|-----------|-----------|
|Flask|Web framework for the application.|
|Flask-SocketIO|Real-time communication for live updates.|
|OpenCV (cv2)|Video capture and processing.|
|MediaPipe|Framework for engagement detection.|
|python-dotenv|Environment variable management.|
|AssemblyAI|API for speech-to-text functionality.|

## ğŸ“œ License
This project is licensed under the MIT License. Feel free to use and modify it for your own projects.
